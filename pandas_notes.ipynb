{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-05T10:41:44.179169500Z",
     "start_time": "2026-01-05T10:41:43.527589600Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Creation of Dataframe\n",
    "df=pd.read_csv('student_csv.csv')\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.describe())\n",
    "print(df.info())\n",
    "print(df.index)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StudentID     Name  Age Gender Branch  Year  CGPA  Attendance       City\n",
      "0        101    Arjun   18      M    CSE     1   8.2          92  Bangalore\n",
      "1        102    Rahul   19      M    ISE     1   7.5          85     Mysore\n",
      "2        103     Neha   18      F    CSE     1   9.1          96      Delhi\n",
      "3        104    Priya   20      F    ECE     2   8.7          90    Chennai\n",
      "4        105  Karthik   21      M     ME     3   6.9          78  Hyderabad\n",
      "   StudentID    Name  Age Gender Branch  Year  CGPA  Attendance        City\n",
      "5        106   Aditi   19      F    CSE     2   9.3          98      Mumbai\n",
      "6        107   Rohan   22      M     CE     4   7.2          80        Pune\n",
      "7        108   Sneha   20      F    EEE     2   8.0          88  Coimbatore\n",
      "8        109  Vikram   21      M    CSE     3   8.5          91   Bangalore\n",
      "9        110  Ananya   18      F    ISE     1   9.0          95     Kolkata\n",
      "       StudentID        Age       Year       CGPA  Attendance\n",
      "count   10.00000  10.000000  10.000000  10.000000   10.000000\n",
      "mean   105.50000  19.600000   2.000000   8.240000   89.300000\n",
      "std      3.02765   1.429841   1.054093   0.830261    6.650814\n",
      "min    101.00000  18.000000   1.000000   6.900000   78.000000\n",
      "25%    103.25000  18.250000   1.000000   7.625000   85.750000\n",
      "50%    105.50000  19.500000   2.000000   8.350000   90.500000\n",
      "75%    107.75000  20.750000   2.750000   8.925000   94.250000\n",
      "max    110.00000  22.000000   4.000000   9.300000   98.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   StudentID   10 non-null     int64  \n",
      " 1   Name        10 non-null     object \n",
      " 2   Age         10 non-null     int64  \n",
      " 3   Gender      10 non-null     object \n",
      " 4   Branch      10 non-null     object \n",
      " 5   Year        10 non-null     int64  \n",
      " 6   CGPA        10 non-null     float64\n",
      " 7   Attendance  10 non-null     int64  \n",
      " 8   City        10 non-null     object \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 852.0+ bytes\n",
      "None\n",
      "RangeIndex(start=0, stop=10, step=1)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Accessing of Data can be done using head tail and etc",
   "id": "d7d598d443198e13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T10:41:44.216703300Z",
     "start_time": "2026-01-05T10:41:44.188169700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.sample(10)\n",
    "\n",
    "#LOC AND ILOC FUNCTIONS\n",
    "print(df.loc[[0,2,4,5]])   #a LIST OF ROWS\n",
    "print(df.loc[0:3])         #A slice of rows\n",
    "print(df.loc[0:5,'StudentID'])  #Range of rows with a specific column\n",
    "#df.loc[0:[list of columns]] gives a range of columns for a specific rows\n",
    "df.iloc[0:20,:]   #Same shi but like with indexes on both sides\n"
   ],
   "id": "2bef24d4b0278764",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (53918155.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mprint(df.loc[[0,2,5]])4,   #a LIST OF ROWS\u001B[39m\n                          ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# To convert the index column into the specific column\n",
   "id": "e53ac1a01ce9c816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.index=df['StudentID']\n",
    "#Now instead of using the index values for rows u can use specific row names\n"
   ],
   "id": "5bac174ff49122d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#   u    can sort values of a column based on parameters\n",
   "id": "2ac82e4f1b1b113b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df1=df.copy()\n",
    "df1.sort_values('Attendance', ascending=False)\n",
    "df1"
   ],
   "id": "2344464099b68db8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  A case where u might need to iterate through rows\n",
   "id": "cd2e7e66a0d7a990"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for index,rows in df.iterrows():\n",
    "    print(rows['StudentID'])\n"
   ],
   "id": "5a2b32973a5c78ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Filtering data",
   "id": "1b3e049b7a67e819"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#df[' lap_time_seconds']=pd.to_numeric(df[' lap_time_seconds'],errors='coerce')\n",
    "df[(df['Attendance']>80.555) & (df['Attendance']<100.000)] #Basically vectorized operations but u gotta define it inside a df[can be a logical expression ]\n",
    "df[(df['Attendance']>80.555) & (df['Attendance']<100.000)]['Name']  #Does the same thing but the second set of [] helps to only print a select columns defined within []\n",
    "df.loc[df['Attendance']>80.555,['Name']]\n",
    "\n"
   ],
   "id": "99e197bbb47c2cf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Filtering using string operations\n",
    "    -Assume u have a dataset df having a column 'NAME' and u want to pick up strings that start with the word 'real' then u use\n",
    "     df[df['NAME'].str.contains('real')]'''\n",
    "     -contains() accepts a parameter case  ->True if u need it to be case sensitive and false if not\n",
    "     -U can use regex as the string to find\n",
    "\n"
   ],
   "id": "a1e990a8c416b8b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # isin filter\n",
    " ### given column or list of columns isin function checks the membership of elements of this column in the given parameter and conditions can also be passed\n",
    " ### Ex: df[df['born_country'].isin(['USA','FRA'] & df['name']=='Samuel']"
   ],
   "id": "e44c2aaa7fbb9472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df['Branch'].isin(['CSE','ISE'])]",
   "id": "33d01d867579d555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Adding/Removing Columns\n",
    "## Adding a new column can just be done by writing df['new_column_name']=A list of elements to be stored as a column\n",
    "\n",
    "## For removing we use df.drop()\n",
    "    -drop() defualt does not modify og dataframe but can be modified by using the inplce paramter to be True"
   ],
   "id": "ef8ae26461f6a2ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Converting a list of dates to datetime column\n",
    "    -df['dob']=pd.to_datetime(df['dob']\n",
    "\n",
    "## To access methods of a datetime object u use .dt.year, dt.day, dt.month etc"
   ],
   "id": "5863960a85aee035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Saving a dataframe into a required file\n",
   "id": "3aea265ec902bc4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df1.to_csv('C:\\\\Users\\ASUS\\PyCharmMiscProject\\Python pactice for motorsport\\student_csv.csv',index=False) #Index=False means it wont create a new column just for the index values\n",
   "id": "3d2ba50458daa276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply Function",
   "id": "77f7257213c4bac7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['CODE']=df['City'].apply(lambda x:str(x)[0:3].upper())       #Always takes a function as the main arguement can have a parameter axis =0 or 1 to perform operations on all rows and all columns\n",
    "df"
   ],
   "id": "a96452f371bf4515",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# pd.concat() is a function that receives a list of files (csv or excel etc) and merge them together\n",
   "id": "db05299da7e745b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5b5ab33a63f42d4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Handling Null Values",
   "id": "efb42027761210dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# lets change the cities of 2 ppl to NaN\n",
    "df.loc[0:1,'City']=pd.NA\n",
    "\n",
    "\n",
    "#To fill said Na values use .fillna()\n",
    "df['City'].fillna('Ranchi')\n",
    "print(df.head())\n",
    "\n",
    "#If there is a series of continuation u can fill in the Na values with the .interpolate() function\n",
    "#It looks at the neibouring values up and down and just gives a prediction of what the value might be\n",
    "\n",
    "# U can use dropna() to drop the rows which contains NaN Values\n",
    "# If u wanna drop rows only if a specific column or specific columns have nan then u define subset=[the columns u want that have nan values]\n",
    "\n",
    "# to get the rows that have nan values\n",
    "df[df['City'].isna()]\n",
    "\n",
    "# to get rows that dont have Na values is done by writing .notna()\n",
    "\n"
   ],
   "id": "34211075f8e3abd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Aggregation: Getting a count of values present in the given data",
   "id": "df35e93b3b7f9dd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "li=df['Gender'].value_counts().to_dict()    #li is a series object\n",
    "print(li)\n"
   ],
   "id": "42eb495527c3b57c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Group By function\n",
   "id": "72b1ecc1890782c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby(['Branch']).agg({'CGPA':['mean','max','min'],'Attendance':['max','min']})",
   "id": "edb8519a201d3efa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# .agg() function",
   "id": "4a40f44d86529d65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['CGPA'].agg(['mean','std','min','max'])",
   "id": "3c2c0b2b822104cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3ed69882661d3ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Practice Questions:\n",
    "\n",
    "##  Q1:for each driver and avg laptimes"
   ],
   "id": "a2c765c57518dbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Driver': ['Max', 'Max', 'Lewis', 'Lewis', 'Charles', 'Charles'],\n",
    "    'Lap': [1, 2, 1, 2, 1, 2],\n",
    "    'LapTime': [72.1, 71.8, 73.0, 72.6, 72.9, 72.4],\n",
    "    'Tyre': ['Soft', 'Soft', 'Medium', 'Medium', 'Soft', 'Medium']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.groupby(['Driver'])['LapTime'].agg(['min','max','mean'])\n"
   ],
   "id": "e3191ed7b70a36a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Q2:Filtering & Conditions\n",
    "Using the DataFrame above:\n",
    "\n",
    "Extract all drivers with lap times less than the average lap time.\n",
    "\n",
    "#  GroupBy Operation: (CONTAIND IDXMIN() IT IS IMP)*****\n",
    "Given a DataFrame with columns:\n",
    "\n",
    "Team\n",
    "\n",
    "LapTime\n",
    "\n",
    "Find the average lap time per team.\n",
    "\n",
    "Identify the team with the fastest average lap.\n",
    "\n",
    "Handling Missing Data\n",
    "A column TyreWear contains missing (NaN) values.\n",
    "\n",
    "Replace missing values with the column mean.\n",
    "\n",
    "Then normalize the column between 0 and 1."
   ],
   "id": "fe24c42a5e30c7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lap_data = {\n",
    "    \"Timestamp\": [\n",
    "        \"2026-01-04 10:00:00\",\n",
    "        \"2026-01-04 10:01:00\",\n",
    "        \"2026-01-04 10:02:00\",\n",
    "        \"2026-01-04 10:03:00\",\n",
    "        \"2026-01-04 10:04:00\",\n",
    "        \"2026-01-04 10:05:00\",\n",
    "        \"2026-01-04 10:06:00\",\n",
    "        \"2026-01-04 10:07:00\"\n",
    "    ],\n",
    "    \"Driver\": [\n",
    "        \"Verstappen\",\n",
    "        \"Hamilton\",\n",
    "        \"Norris\",\n",
    "        \"Leclerc\",\n",
    "        \"Piastri\",\n",
    "        \"Perez\",\n",
    "        \"Alonso\",\n",
    "        \"Russell\"\n",
    "    ],\n",
    "    \"Team\": [\n",
    "        \"Red Bull\",\n",
    "        \"Ferrari\",\n",
    "        \"McLaren\",\n",
    "        \"Ferrari\",\n",
    "        \"McLaren\",\n",
    "        \"Red Bull\",\n",
    "        \"Aston Martin\",\n",
    "        \"Mercedes\"\n",
    "    ],\n",
    "    \"LapTime\": [\n",
    "        91.2, 92.1, 90.8, 91.5, 91.0, 92.4, 93.1, 91.7\n",
    "    ],\n",
    "    \"TyreWear\": [\n",
    "        0.35, None, 0.29, 0.33, None, 0.41, 0.45, 0.38\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(lap_data)\n",
    "avg_lap_time=df['LapTime'].mean()\n",
    "print(df[df['LapTime']<avg_lap_time])\n",
    "print()\n",
    "#q4\n",
    "df['TyreWear'].fillna(df['TyreWear'].mean())\n",
    "print(df.head())\n",
    "\n",
    "#q3\n",
    "print(df.groupby(['Team']).agg({'LapTime':'mean'}))\n",
    "print()\n",
    "v=df.groupby(['Team']).agg({'LapTime':'mean'})['LapTime'].idxmin()\n",
    "print(f'Fastest Team:{v}')"
   ],
   "id": "3d17e6aa4d7faa6f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
